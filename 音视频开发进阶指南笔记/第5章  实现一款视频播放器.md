## 架构设计

<img src="https://s2.loli.net/2022/12/28/WzGC6m83Z5BgTk9.png" alt="image.png" style="zoom:33%;" />

![image.png](https://s2.loli.net/2022/12/28/7tm2fB9dnV6HYTz.png)

AudioOutput：音频输出模块

VideoOutput：视频输出模块

AVSynchronizer：音视频同步模块

AudioFrame：音频帧

AudioFrameQueue：音频队列

VideoFrame：视频帧

VideoFrameQueue：视频队列

VideoDecoder：输入模块

## 输入模块

这一模块的主要职责是，连接资源，并将输入的资源进行解封装、解码。直接使用FFmpeg进行协议解析、封装格式拆分，解码操作。整个运行流程如下：

+ 建立连接、准备资源

+ 不断读取数据进行解封装、解码、处理数据

+ 释放资源

  <img src="https://flyer-blog.oss-cn-shenzhen.aliyuncs.com/ffmpeg%E8%A7%A3%E5%B0%81%E8%A3%85%E6%B5%81%E7%A8%8B.drawio.png" alt="ffmpeg解封装流程图" style="zoom:50%;" />

### 容易内存泄漏的点：

+ av_read_frame(fmtCtx, packet); 这个函数用于从formatContext的流数据中，读取一个packet的数据。根据官方文档的解释，packet内部的packet指针会新malloc一块缓冲区，用来存储读取到的数据。所以每次用完这个packet的数据之后，都要调用av_packet_unref(packet);方法，将那块缓冲区释放掉。否则会导致内存泄漏
+ Avcodec_receive_frame()方法，会读解码器中读取一个音频帧的数据。原理同上，也需要调用av_frame_unref(frame);的方法，将frame内部的缓冲区及时释放掉。

### 格外注意数据的格式，会影响其编解码出来后的形式

首先要区分好plannar和packed两种格式。

plannaer，左右声道是分开存储的，LLLLLLRRRRRRR

如果有一个uint8_t **outdata 负责存储数据。

则outdata[0]是第一个声道的数据;outdate[1]是第二个声道的数据，以此类推

而对于packed，左右声道交叉存储，LRLRLRLRLR

则数据全部存储在outdata[0]中，outdata[1]为空。

所以当我们设置了重采样的目标格式之后，得到的outdata的数据分布情况，就会根据是plannar还是packed而定，从而我们在用outdata写文件的时候，就要区分好。

### 一个总结

在数据解码的时候，主要思考这样几个点：

1. 输入的数据是什么格式的？
2. 输入的数据，解码之后，是什么格式的？比如音频的话一般会解码为s16p,视频的话一般解码为yuv420p。 尤其要注意，数据是否带p，这将影响数据的读取方式。
3. 想要转换存储的数据是什么格式的。

把第二点做好，可以避免很多无用功。